{
 "cells": [
  {
   "source": [
    "# Extract Performances"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict"
   ]
  },
  {
   "source": [
    "## Define DefaultOrderedDict"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/wooks/anaconda3/envs/avidnet/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict, Callable\n",
    "\n",
    "class DefaultOrderedDict(OrderedDict):\n",
    "    # Source: http://stackoverflow.com/a/6190500/562769\n",
    "    def __init__(self, default_factory=None, *a, **kw):\n",
    "        if (default_factory is not None and\n",
    "           not isinstance(default_factory, Callable)):\n",
    "            raise TypeError('first argument must be callable')\n",
    "        OrderedDict.__init__(self, *a, **kw)\n",
    "        self.default_factory = default_factory\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        try:\n",
    "            return OrderedDict.__getitem__(self, key)\n",
    "        except KeyError:\n",
    "            return self.__missing__(key)\n",
    "\n",
    "    def __missing__(self, key):\n",
    "        if self.default_factory is None:\n",
    "            raise KeyError(key)\n",
    "        self[key] = value = self.default_factory()\n",
    "        return value\n",
    "\n",
    "    def __reduce__(self):\n",
    "        if self.default_factory is None:\n",
    "            args = tuple()\n",
    "        else:\n",
    "            args = self.default_factory,\n",
    "        return type(self), args, None, None, self.items()\n",
    "\n",
    "    def copy(self):\n",
    "        return self.__copy__()\n",
    "\n",
    "    def __copy__(self):\n",
    "        return type(self)(self.default_factory, self)\n",
    "\n",
    "    def __deepcopy__(self, memo):\n",
    "        import copy\n",
    "        return type(self)(self.default_factory,\n",
    "                          copy.deepcopy(self.items()))\n",
    "\n",
    "    def __repr__(self):\n",
    "        return 'OrderedDefaultDict(%s, %s)' % (self.default_factory,\n",
    "                                               OrderedDict.__repr__(self))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract mean best scores among all random seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = './results/baseline/nl50'\n",
    "# input_dir = './results/fixmatch/nl50'\n",
    "# input_dir = './results/fixmatch&focal/nl50/0.5'\n",
    "out_dir = './results'\n",
    "out_fname = 'test.csv'\n",
    "if not os.path.isdir(out_dir):\n",
    "    os.makedirs(out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'./results/baseline/nl50/baseline-b16-nl50-m1-lb1.0-th1.0-sharpFalse-T1.0-focalFalse-fg1.0-optSGD-lr0.001-mom0.9-sc:step-r1.txt'"
      ]
     },
     "metadata": {},
     "execution_count": 144
    }
   ],
   "source": [
    "\n",
    "# Extract paths for each colums\n",
    "ori_data_paths = glob.glob(f'{input_dir}/*.txt')\n",
    "data_paths_dict, fm_cols = DefaultOrderedDict(list), []\n",
    "for ori_data_path in ori_data_paths:\n",
    "    # Exclude the case of the random seed 4 because of performance\n",
    "    if 'baseline' in ori_data_path:\n",
    "        data_paths_dict['baseline'].append(ori_data_path)\n",
    "        if 'baseline' not in fm_cols:\n",
    "            fm_cols.append('baseline')\n",
    "    else: # FixMatch\n",
    "        cond = ori_data_path.split('/')[-1]\n",
    "        for r in range(4):\n",
    "            cond = cond.replace(f'-r{r}', '')\n",
    "\n",
    "        data_paths_dict[cond].append(ori_data_path)\n",
    "        if cond not in fm_cols:\n",
    "            fm_cols.append(cond)\n",
    "\n",
    "data_paths_dict['baseline'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                   acc-all           ppv-all         ppv-covid  \\\n",
       "baseline  0.8525 (±0.0197)  0.8590 (±0.0146)  0.9138 (±0.0248)   \n",
       "\n",
       "             ppv-pneumonia        ppv-normal        recall-all  \\\n",
       "baseline  0.8274 (±0.0637)  0.8357 (±0.0349)  0.8525 (±0.0197)   \n",
       "\n",
       "              recall-covid  recall-pneumonia     recall-normal  \\\n",
       "baseline  0.8367 (±0.0578)  0.8750 (±0.0328)  0.8458 (±0.0528)   \n",
       "\n",
       "                    f1-all          f1-covid      f1-pneumonia  \\\n",
       "baseline  0.8528 (±0.0196)  0.8718 (±0.0251)  0.8479 (±0.0227)   \n",
       "\n",
       "                 f1-normal  \n",
       "baseline  0.8388 (±0.0187)  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>acc-all</th>\n      <th>ppv-all</th>\n      <th>ppv-covid</th>\n      <th>ppv-pneumonia</th>\n      <th>ppv-normal</th>\n      <th>recall-all</th>\n      <th>recall-covid</th>\n      <th>recall-pneumonia</th>\n      <th>recall-normal</th>\n      <th>f1-all</th>\n      <th>f1-covid</th>\n      <th>f1-pneumonia</th>\n      <th>f1-normal</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>baseline</th>\n      <td>0.8525 (±0.0197)</td>\n      <td>0.8590 (±0.0146)</td>\n      <td>0.9138 (±0.0248)</td>\n      <td>0.8274 (±0.0637)</td>\n      <td>0.8357 (±0.0349)</td>\n      <td>0.8525 (±0.0197)</td>\n      <td>0.8367 (±0.0578)</td>\n      <td>0.8750 (±0.0328)</td>\n      <td>0.8458 (±0.0528)</td>\n      <td>0.8528 (±0.0196)</td>\n      <td>0.8718 (±0.0251)</td>\n      <td>0.8479 (±0.0227)</td>\n      <td>0.8388 (±0.0187)</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 145
    }
   ],
   "source": [
    "p = re.compile('1[.]\\d{4}|0[.]\\d{4}') #[0.숫자4개]\n",
    "\n",
    "cols = ('acc-all', 'ppv-all', 'ppv-covid', 'ppv-pneumonia', 'ppv-normal',\n",
    "        'recall-all', 'recall-covid', 'recall-pneumonia', 'recall-normal',\n",
    "        'f1-all', 'f1-covid', 'f1-pneumonia', 'f1-normal')\n",
    "metrics_dfs = {}\n",
    "for col, data_paths in data_paths_dict.items(): # 데이터 경로에서 txt파일을 하나씩 불러온다.\n",
    "    metrics_dfs[col] = pd.DataFrame([], columns=cols)\n",
    "    for ori_data_path in data_paths:\n",
    "\n",
    "        with open(ori_data_path, 'r') as f: \n",
    "            all_data = f.read() # 전체 txt line을 읽어온다.\n",
    "            all_data = all_data.split('\\n') # 띄어쓰기 기준으로 나눔\n",
    "            if 'baseline' in ori_data_path:\n",
    "                candidates = ((327, 332), (662, 667), (997, 1002),)\n",
    "                              #(1332, 1337))#, (1667, 1672))\n",
    "            else:\n",
    "                candidates = ((347, 352), (702, 707), (1057, 1062),)\n",
    "                              #(1412, 1417))#, (1767, 1772))\n",
    "            metrics = []\n",
    "            for s_idx, e_idx in candidates:\n",
    "                metric_line = all_data[s_idx:e_idx] # hard coding.. best result 부분\n",
    "                metrics.append(list(map(float, p.findall(str(metric_line)))))# 정규표현식에 맞는것만 뽑기\n",
    "\n",
    "            metrics_dfs[col] = pd.concat((metrics_dfs[col],\n",
    "                                         pd.DataFrame(metrics, columns=cols))).reset_index(drop=True)\n",
    "\n",
    "final_metrics_df = pd.DataFrame([], columns=cols)\n",
    "for fm_col in fm_cols:\n",
    "    final_metrics = []\n",
    "    for col in cols:\n",
    "        best_metrics = metrics_dfs[fm_col][col].to_numpy()\n",
    "        mean, std = best_metrics.mean(), best_metrics.std()\n",
    "        final_metrics.append(f'{mean:.4f} (±{std:.4f})')\n",
    "        \n",
    "    final_metrics_df = final_metrics_df.append(pd.DataFrame([final_metrics], columns=cols, index=(fm_col,)))\n",
    "\n",
    "final_metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_metrics_df.to_csv(f'{out_dir}/{out_fname}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python379jvsc74a57bd0d3acb0562c68345cb9a4a86bfb748e0443e62343e02c94a7f79b6c1904f54bbb",
   "display_name": "Python 3.7.9 64-bit ('avidnet': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "metadata": {
   "interpreter": {
    "hash": "d3acb0562c68345cb9a4a86bfb748e0443e62343e02c94a7f79b6c1904f54bbb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}